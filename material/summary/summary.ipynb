{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Flatten, Conv2D, MaxPool2D\n",
    "from keras.datasets import mnist\n",
    "from keras.utils import to_categorical\n",
    "import numpy as np \n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CNN (딥러닝)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 데이터셋 로드\n",
    "(X_train, y_train), (X_test, y_test) = mnist.load_data()\n",
    "print(X_train.shape) ## (60000, 28, 28) 이미지수, 높이, 너비\n",
    "\n",
    "# CNN 입력을 위한 Reshape\n",
    "X_train = X_train.reshape(X_train.shape[0], 28, 28, 1)\n",
    "X_test = X_test.reshape(X_test.shape[0], 28, 28, 1)\n",
    "\n",
    "# 독립변수 정규화 (r, g, b) 0~255 -> 0~1\n",
    "X_train = X_train.astype('float32')\n",
    "X_test = X_test.astype('float32')\n",
    "X_train /= 255\n",
    "X_test /= 255\n",
    "\n",
    "# 목표변수 One-Hot Encoding 처리\n",
    "Y_train = to_categorical(y_train, 10)\n",
    "Y_test = to_categorical(y_test, 10)\n",
    "\n",
    "# 모델 생성\n",
    "model = Sequential()\n",
    "model.add(Conv2D(32,(3,3),activation='relu', input_shape=(28, 28, 1))) # 합성곱 연산 수행\n",
    "model.add(Conv2D(32, (3,3), activation='relu'))\n",
    "model.add(MaxPool2D(pool_size=(2, 2))) # 2x2 max pooling\n",
    "model.add(Dropout(0.25))\n",
    "model.add(Flatten()) # 1차원으로 변환\n",
    "model.add(Dense(128, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(10, activation='softmax'))\n",
    "print(model.summary())\n",
    "\n",
    "# 모델 컴파일\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "# 모델 학습\n",
    "history = model.fit(X_train, Y_train, batch_size=32, epochs=10, verbose=1)\n",
    "\n",
    "# 모델 평가\n",
    "score = model.evaluate(X_test, Y_test, verbose=0)\n",
    "print(model.metrics_names)\n",
    "print(score)\n",
    "\n",
    "# 성능 지표 시각화\n",
    "acc = history.history['accuracy']\n",
    "loss = history.history['loss']\n",
    "epoch_range = range(1, len(acc)+1)\n",
    "\n",
    "## Loss\n",
    "plt.plot(epoch_range, loss, 'b', label='Training loss')\n",
    "plt.title('Training loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "plt.figure()\n",
    "\n",
    "## Accuracy\n",
    "plt.plot(epoch_range, acc, 'b', label='Training acc')\n",
    "plt.title('Training accuracy')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend()\n",
    "plt.figure()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 결측치 처리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('salesdata.csv')\n",
    "\n",
    "# Null value를 가진 컬럼 확인 & Null value의 수 확인\n",
    "df.info()\n",
    "df.isnull().sum()\n",
    "(df.isnull().sum() / df.shape[0]) * 100 ## Null 비율\n",
    "\n",
    "# 고유값 확인\n",
    "for col in df.columns:\n",
    "    print(col, df[col].unique())\n",
    "\n",
    "# (참고) 기초 시각화\n",
    "import seaborn as sns\n",
    "sns.countplot(x='BikeBuyer', data=df) ## countplot\n",
    "sns.histplot(x='AvgMonthSpend', data=df) ## histplot\n",
    "\n",
    "# 결측값이 있는 행 제거\n",
    "df.dropna(subset=['column명'], inplace=True) ## 특정 칼럼에 결측값이 있을 경우 해당 행을 제거\n",
    "\n",
    "# 결측행 채우기\n",
    "df.fillna('값', inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 레이블 인코딩"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**레이블 인코딩**\n",
    "\n",
    "레이블 인코딩이란?\n",
    "레이블 인코딩은 범주형 데이터 (보통 서열 척도)를 숫자로 변환하는 기법입니다. \n",
    "\n",
    "예를 들어, '사과', '바나나', '체리'라는 범주형 데이터가 있을 때, \n",
    "이를 각각 0, 1, 2로 변환할 수 있습니다. (영어 > 한글 사전순)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# 데이터 로드\n",
    "items=['TV','냉장고','전자렌지','컴퓨터','선풍기','선풍기','믹서','믹서']\n",
    "\n",
    "# 인코딩 변환\n",
    "encoder = LabelEncoder() ## 인코더 초기화\n",
    "encoder.fit(items) ## 학습\n",
    "labels = encoder.transform(items) ## 문자열 -> 인코딩된 숫자로 변환\n",
    "print('인코딩 변환값:',labels)\n",
    "\n",
    "# 인코딩 클래스 확인\n",
    "print('인코딩 클래스:',encoder.classes_)\n",
    "\n",
    "# 디코딩\n",
    "print('디코딩 원본 값:',encoder.inverse_transform([4, 5, 2, 0, 1, 1, 3, 3]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 원 핫 인코딩과 Min-Max 스케일링"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**원 핫 인코딩(One-Hot Encoding)**\n",
    "\n",
    "원 핫 인코딩(One-Hot Encoding)은 범주형 데이터 (주로 명목 척도)를 수치형 데이터로 변환하는 기법 중 하나입니다.\n",
    "이 방법은 각 범주를 고유한 이진 벡터로 변환합니다.\n",
    "예를 들어, '빨강', '초록', '파랑'이라는 세 가지 범주가 있을 때,\n",
    "이를 원 핫 인코딩하면 다음과 같이 변환됩니다:\n",
    "\n",
    "빨강: [1, 0, 0]\n",
    "초록: [0, 1, 0]\n",
    "파랑: [0, 0, 1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Min-Max 스케일링 (Min-Max Scaling)**\n",
    "\n",
    "Min-Max 스케일링은 데이터의 값을 0과 1 사이의 값으로 변환하는 정규화 기법입니다.\n",
    "```\n",
    "수식: X_scaled = (X - X_min) / (X_max - X_min)\n",
    "```\n",
    "\n",
    "\n",
    "이 외에 정규화, Feature Scaling 등이 있습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# 원핫 인코딩\n",
    "df = pd.DataFrame({'item':['TV','냉장고','전자렌지','컴퓨터','선풍기','선풍기','믹서','믹서'] })\n",
    "pd.get_dummies(df, columns=['item'])\n",
    "  # 해당 칼럼을 원핫인코딩으로 변환 (기존 칼럼은 제거)\n",
    "\n",
    "# Min-Max 스케일링\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "scaler = MinMaxScaler()\n",
    "scaler.fit(df)  # min과 max를 계산\n",
    "scaler_df_scaled_array = scaler.transform(df) # numpy.ndarray로 반환\n",
    "scaler_df_scaled = pd.DataFrame(scaler_df_scaled_array, columns=df.columns.tolist())\n",
    "print(scaler_df_scaled)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dm-3-12",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
